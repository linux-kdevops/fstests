#! /bin/bash
# SPDX-License-Identifier: GPL-2.0
# Copyright (C) 2024 Luis Chamberlain. All Rights Reserved.
#
# FS QA Test No. 750
#
# stress page cache truncation + writeback
#
# This aims at trying to reproduce a difficult to reproduce bug found with
# min order. The issue was root caused to an xarray bug when we split folios
# to another order other than 0. This functionality is used to support min
# order. The crash:
#
# https://gist.github.com/mcgrof/d12f586ec6ebe32b2472b5d634c397df
#
# This may also find future truncation bugs in the future, as truncating any
# mapped file through the collateral of using echo 1 > split_huge_pages will
# always respect the min order. Truncating to a larger order then is excercised
# when this test is run against any filesystem LBS profile or an LBS device.
#
# If you're enabling this and want to check underneath the hood you may want to
# enable:
#
# dyndbg='file mm/huge_memory.c +p'
#
# This tests aims at increasing the rate of successful truncations so we want
# to increase the value of thp_split_page in $seqres.full. Using echo 1 >
# split_huge_pages is extremely aggressive, and even accounts for anonymous
# memory on a system, however we accept that tradeoff for the efficiency of
# doing the work in-kernel for any mapped file too. Our general goal here is to
# race with folio truncation + writeback.

. ./common/preamble

_begin_fstest auto long_rw stress soak smoketest

# Override the default cleanup function.
_cleanup()
{
	cd /
	rm -f $tmp.*
	rm -f $runfile
	kill -9 $split_huge_pages_files_pid > /dev/null 2>&1
}

fio_config=$tmp.fio
fio_out=$tmp.fio.out

# real QA test starts here
_supported_fs generic
_require_test
_require_scratch
_require_debugfs
_require_split_debugfs
_require_command "$KILLALL_PROG" "killall"
_fixed_by_git_commit kernel 2a0774c2886d \
	"XArray: set the marks correctly when splitting an entry"

# we need buffered IO to force truncation races with writeback in the
# page cache
cat >$fio_config <<EOF
[force_large_large_folio_parallel_writes]
nrfiles=10
direct=0
bs=4M
group_reporting=1
filesize=1GiB
readwrite=write
fallocate=none
numjobs=$(nproc)
directory=$SCRATCH_MNT
runtime=100*${TIME_FACTOR}
time_based
EOF

_require_fio $fio_config

echo "Silence is golden"

_scratch_mkfs >>$seqres.full 2>&1
_scratch_mount >> $seqres.full 2>&1

# used to let our loops know when to stop
runfile="$tmp.keep.running.loop"
touch $runfile

# The background ops are out of bounds, the goal is to race with fsstress.

# Force folio split if possible, this seems to be screaming for MADV_NOHUGEPAGE
# for large folios.
while [ -e $runfile ]; do
	_split_huge_pages_all >/dev/null 2>&1
done &
split_huge_pages_files_pid=$!

split_count_before=0
split_count_failed_before=0

if grep -q thp_split_page /proc/vmstat; then
	split_count_before=$(grep ^thp_split_page /proc/vmstat | head -1 | awk '{print $2}')
	split_count_failed_before=$(grep ^thp_split_page_failed /proc/vmstat | head -1 | awk '{print $2}')
else
	echo "no thp_split_page in /proc/vmstat" >> $seqres.full
fi

# we blast away with large writes to force large folio writes when
# possible.
echo -e "Running fio with config:\n" >> $seqres.full
cat $fio_config >> $seqres.full
$FIO_PROG $fio_config --alloc-size=$(( $(nproc) * 8192 )) --output=$fio_out

rm -f $runfile

wait > /dev/null 2>&1

if grep -q thp_split_page /proc/vmstat; then
	split_count_after=$(grep ^thp_split_page /proc/vmstat | head -1 | awk '{print $2}')
	split_count_failed_after=$(grep ^thp_split_page_failed /proc/vmstat | head -1 | awk '{print $2}')
	thp_split_page=$((split_count_after - split_count_before))
	thp_split_page_failed=$((split_count_failed_after - split_count_failed_before))

	echo "vmstat thp_split_page: $thp_split_page" >> $seqres.full
	echo "vmstat thp_split_page_failed: $thp_split_page_failed" >> $seqres.full
fi

status=0
exit
